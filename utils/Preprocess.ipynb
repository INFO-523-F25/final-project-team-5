{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f685faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "stock_data = pd.read_csv('data/stock_data.csv')\n",
    "unemployment = pd.read_csv('data/SeriesReport.csv')\n",
    "#print('stock_data (head):')\n",
    "#print(stock_data.head())   \n",
    "\n",
    "# Converting the Observation Date Variable to a Datetime Variable\n",
    "stock_data['dt'] = pd.to_datetime(stock_data['dt'])\n",
    "\n",
    "# Unpivoting the Unemployment Data\n",
    "unemployment_unpivot = unemployment.melt(id_vars='Year', var_name='Month', value_name='Unemployment Percent')\n",
    "\n",
    "# Extracting the Year and Month from the Observation Date\n",
    "stock_data['Year'] = stock_data['dt'].dt.year\n",
    "stock_data['Month'] = stock_data['dt'].dt.month\n",
    "\n",
    "# Replacing the Month Words with Month Numbers\n",
    "month_replacement = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "\n",
    "# Apply the mapping\n",
    "unemployment_unpivot['Month'] = unemployment_unpivot['Month'].map(month_replacement)\n",
    "\n",
    "# Merging the two DataFrames Together\n",
    "stock_data_final = pd.merge(stock_data, unemployment_unpivot, on = ['Year', 'Month'], how = 'left')\n",
    "\n",
    "# Returning the First Five Records\n",
    "stock_data_final.head()\n",
    "\n",
    "categorical_cols = stock_data_final.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = stock_data_final.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "#print(\"Categorical columns:\", categorical_cols)\n",
    "#print(\"Numerical columns:\", numerical_cols)\n",
    "\n",
    "# Calculating Skewness for Numerical Columns\n",
    "numeric_data=stock_data_final[numerical_cols]\n",
    "\n",
    "skew_array = skew(numeric_data, axis=0, bias=False, nan_policy='omit')\n",
    "skew_value = pd.Series(skew_array, index=numerical_cols)\n",
    "\n",
    "print(\"\\nSkewness (scipy) for numeric columns:\")\n",
    "print(skew_value)\n",
    "\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(stock_data_final[col].dropna(), bins=30)\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#Correlation\n",
    "corr_matrix = stock_data_final[numerical_cols].corr()\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(corr_matrix)\n",
    "\n",
    "#sp500 & djia, sp500_volume & djia_volume, are highly correlated (>0.9). "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
